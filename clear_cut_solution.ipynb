{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/justinetaylor/mids-w207-final-project/blob/yang_branch/clear_cut_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WzBQrcO0RBF7"
   },
   "source": [
    "# Forest Cover Type Prediction\n",
    "#### Team: Clear-Cut Solution: Kevin Martin, Yang Jing, Justine Schabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup\n",
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "id": "E1mvKJRoRBF8"
   },
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# Libraries for reading, cleaning and plotting the dataa\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Libraries for models \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wKC7Up6cRZ9P",
    "outputId": "7e26f8f0-09e0-4c22-ed49-b7649373c3bf"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'CLOUDSDK_CONFIG'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-228-788a3662f10d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Mount the drive for file storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m   \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m   \u001b[0mhome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhome\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m   \u001b[0mroot_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_env\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0mhome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HOME'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m   root_dir = _os.path.realpath(\n\u001b[0;32m---> 43\u001b[0;31m       _os.path.join(_os.environ['CLOUDSDK_CONFIG'], '../..'))\n\u001b[0m\u001b[1;32m     44\u001b[0m   \u001b[0minet_family\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'IPV4_ONLY'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m   \u001b[0mdev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/dev/fuse'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'CLOUDSDK_CONFIG'"
     ]
    }
   ],
   "source": [
    "# Mount the drive for file storage\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RMm1QtRyRMfz"
   },
   "outputs": [],
   "source": [
    "os.chdir('/content/drive/My Drive/W207-Final-Project')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LjWPqxyfRBGB"
   },
   "outputs": [],
   "source": [
    "# Read in training data \n",
    "train_df = pd.read_csv(\"data/train.csv\")\n",
    "test_df = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IxY0GuvrRBGA"
   },
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gh_KrLC6RBGD"
   },
   "source": [
    "First, we check the data attributes, quality and shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "deE2OUccRBGE",
    "outputId": "2426036b-f2a2-4c3f-b3ef-7c18a7b6dda4"
   },
   "outputs": [],
   "source": [
    "# Examine shape \n",
    "print(train_df.shape)\n",
    "\n",
    "# Briefly examine feature attributes for the training data \n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UhhbPQS515l7",
    "outputId": "61747f0f-1484-43b8-af5c-c0037359df73"
   },
   "outputs": [],
   "source": [
    "# Check data types\n",
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify Dataset Is Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "id": "Vguj0panBtwr",
    "outputId": "e7db49f2-f020-4e36-91f7-73e92306f033"
   },
   "outputs": [],
   "source": [
    "# Visualize the distribution of labels, \"Cover_Type\"\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.displot(train_df[\"Cover_Type\"],rug=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOQRzKxhRBGK"
   },
   "source": [
    "Here we can see that the training data has a somewhat uniform distribution of covertype and this tells us that our data set is balanced. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check For Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xa-tfNWlRBGN",
    "outputId": "efeeb34e-9e27-4b72-c238-bc7b56d4957b"
   },
   "outputs": [],
   "source": [
    "# Check for NA values\n",
    "# `.isna()` returns a df with bools the first `.sum()` returns series, second is int \n",
    "print(\"There are {} NA values in the training data\".format(train_df.isna().sum().sum()))\n",
    "print(\"There are {} NA values in the test data\\n\".format(train_df.isna().sum().sum()))\n",
    "print(\"There are {} values in the training data\".format(train_df.count()[0]))\n",
    "print(\"There are {} values in the test data\".format(test_df.count()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0pnwLrKRBGQ"
   },
   "source": [
    "There are no null values in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distributions of Numeric Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YPRL_TIyByEc"
   },
   "outputs": [],
   "source": [
    "# Collect numeric feature column names - so we can easily access these columns when modifying them \n",
    "num_cols = ['Elevation', 'Slope','Aspect',\n",
    "       'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n",
    "       'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon',\n",
    "       'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 839
    },
    "id": "CF9kPFH6RBGH",
    "outputId": "b62c2ea5-c9d3-4cb5-a362-b6c0089cf82c"
   },
   "outputs": [],
   "source": [
    "# Visualize the distribution of numerical columns\n",
    "col_count = len(num_cols)\n",
    "rows = col_count//2\n",
    "fig, axes = plt.subplots(rows,2,figsize=(20,20))\n",
    "for i in range(col_count):\n",
    "    for j in range(2):\n",
    "        # TODO: Can you explain the index manipulaions with a comment? \n",
    "        col= train_df[num_cols[j+2*(i//2)]]\n",
    "        sns.histplot(col, ax=axes[i//2][j])\n",
    "        axes[i//2][j].grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7H9S_npqSs5x"
   },
   "source": [
    "Here we can see the distribution are skewed for a few variables, espcially in the \"distance\" related ones, such as \"Horizontal_Diestance_To_Fire_points\". A log-transformation may improve the model performance. Also, there are zeros in these variables, we need to add 1 before performing the log transofrmation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 846
    },
    "id": "Ke5_pgIfnfEz",
    "outputId": "37bbabcc-ffed-4aed-bc6d-6de6464c8467"
   },
   "outputs": [],
   "source": [
    "# Visualize the distribution of numerical columns with Cover Type\n",
    "fig, axes = plt.subplots(rows,2,figsize=(20,20))\n",
    "for i in range(col_count):\n",
    "    for j in range(2):\n",
    "        col= train_df[num_cols[j+2*(i//2)]]\n",
    "        sns.violinplot(x=train_df['Cover_Type'], y= col, ax=axes[i//2][j])\n",
    "        axes[i//2][j].grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "792XwyWQRBGN"
   },
   "source": [
    "First, we can see there is a relationship between the cover type and elevation. The difference in the other fetures by cover type seem less significant. Cover type 1 and 2 share a lot of similar features. We need to find a way to magnify the signal between the 2 cover types. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5OtVRtoYJKa"
   },
   "source": [
    "We also see there is not much differences in the relationship between the cover type and Aspect. The Aspect is expressed in degrees, and 0 degree and 360 degree is the same thing but represented differently. This probably contributed to poor distinction among the lables. In feature engineering, we'll extract the sine and cosine values to normalize this feature.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9BnHwhzlvna",
    "outputId": "518f7717-9e3c-45e5-9b90-812020415387"
   },
   "outputs": [],
   "source": [
    "# Rank correlations with \"cover type\"\n",
    "# This was train_corr1=train_df1.corr(), but train_df1 isn't defined yet? - Maybe we can remove this, since we have the heatmap below?\n",
    "train_corr1=train_df.corr()\n",
    "train_corr1['Cover_Type'].abs().sort_values(ascending=False)[:31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 639
    },
    "id": "29Wl0uOpRBGZ",
    "outputId": "f17e7a25-198f-4aa4-fccc-5d4a082358d6"
   },
   "outputs": [],
   "source": [
    "# Explore correlations between numerical features\n",
    "train_corr = train_df[num_cols].corr()\n",
    "\n",
    "# Plot a heat map for correlations\n",
    "ax = plt.figure(figsize=(8,8))\n",
    "sns.heatmap(train_corr, xticklabels=train_corr.columns.values, yticklabels=train_corr.columns.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBpDUmk0BN7K"
   },
   "source": [
    "From the above, \"Hillshade_9am\" has strong correlation with \"Hillshade_3pm\" and \"Aspect\". We may drop this feature to avoid multi-collinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soil Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5FfK9StRBGW"
   },
   "source": [
    "Now, we'll isolate and explore the distribution of soil types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vCZ4WTxmRBGX"
   },
   "outputs": [],
   "source": [
    "# Get a list of categorical column names\n",
    "cat_cols = ['Soil_Type1', 'Soil_Type2', 'Soil_Type3',\n",
    "       'Soil_Type4', 'Soil_Type5', 'Soil_Type6', 'Soil_Type7', 'Soil_Type8',\n",
    "       'Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12',\n",
    "       'Soil_Type13', 'Soil_Type14', 'Soil_Type15', 'Soil_Type16',\n",
    "       'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20',\n",
    "       'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24',\n",
    "       'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28',\n",
    "       'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32',\n",
    "       'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36',\n",
    "       'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40','Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3',\n",
    "       'Wilderness_Area4']\n",
    "\n",
    "soil_cols = cat_cols.copy()\n",
    "soil_cols.append(\"Cover_Type\")\n",
    "soil_df = train_df[soil_cols]\n",
    "\n",
    "# Now we convert the soil type columns back into one column with values as the \"soil type\"\n",
    "soil_df_unpivoted = soil_df.melt(id_vars=\"Cover_Type\",var_name=\"soil_type\",value_name=\"yes\")\n",
    "# Only keep rows of where the \"soil type\" is \"yes\"\n",
    "mask1 = soil_df_unpivoted[\"yes\"] == 1\n",
    "soil_df_unpivoted = soil_df_unpivoted[mask1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "id": "HfAWAaHDK4UH",
    "outputId": "ea16bae9-1eb3-4fdf-9fc8-5b73611049ba"
   },
   "outputs": [],
   "source": [
    "# Visualize cover type VS soil type in a pivot table. \n",
    "df1 = soil_df_unpivoted.groupby([\"Cover_Type\",\"soil_type\"], as_index=False).count()\n",
    "df1 = df1.pivot(\"Cover_Type\",\"soil_type\",\"yes\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cBZtqPu-RBGZ"
   },
   "source": [
    "As we can see in the pivot table above, there are similar combinations of soil types for different \"cover type\". We'll combine the soil types that share same \"cover types\" to reduce dimensionality. Further, \"cover type 1\" and \"cover type 2\" , \"cover type 3\" and \"cover type 6\" share many overlapping features. To magnify the signal, we'll combine features as an extra feature where there is a difference between the 2 pairs of cover types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eKxqY6Q0RBGc"
   },
   "outputs": [],
   "source": [
    "# Visualize the distribution of soil type and \"cover type\"\n",
    "st_list = ['Soil_Type1', 'Soil_Type2', 'Soil_Type3',\n",
    "       'Soil_Type4', 'Soil_Type5', 'Soil_Type6', 'Soil_Type8',\n",
    "       'Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12',\n",
    "       'Soil_Type13', 'Soil_Type14', 'Soil_Type16','Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20',\n",
    "       'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24',\n",
    "       'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28',\n",
    "       'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32',\n",
    "       'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36',\n",
    "       'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40']\n",
    "\n",
    "fig, axes = plt.subplots(19,2,figsize=(24,120))\n",
    "for i in range(len(st_list)):\n",
    "    sns.violinplot(y=train_df['Cover_Type'],x=train_df[st_list[i]], ax=axes[i//2,i%2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYgLWktXRBGe"
   },
   "source": [
    "Here we can examine the relationship between soil type and cover type for each soil type. # TODO: Discuss more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wilderness Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJ_YZ9nKRBGe"
   },
   "source": [
    "Now, we'll isolate and explore the distribution of wilderness types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vMGfIR8MRBGf"
   },
   "outputs": [],
   "source": [
    "wilderness_list =['Wilderness_Area1','Wilderness_Area2','Wilderness_Area3','Wilderness_Area4']\n",
    "\n",
    "# Visualize the distribution of wilderness area and \"cover type\"\n",
    "fig, axes = plt.subplots(2,2,figsize=(24,12))\n",
    "for i in range(4):\n",
    "    sns.violinplot(y=train_df['Cover_Type'],x=train_df[wilderness_list[i]], ax=axes[i//2,i%2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3GrHeyW7VXiz"
   },
   "source": [
    "## Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale Hillshade\n",
    "\n",
    "Now we'll normalize the \"Hillsdale\" variables by dividing them by 255. TODO: Can we explain why? We'll scale them all later? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TpTqdq_5McMv"
   },
   "outputs": [],
   "source": [
    "fe1_cols = ['Hillshade_9am', 'Hillshade_Noon',\n",
    "       'Hillshade_3pm']\n",
    "train_df[fe1_cols] = train_df[fe1_cols]/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create New Soil Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SINIJ7g_k7UG"
   },
   "source": [
    "Now we'll create additional features to magnify the differences betweeen cover type1 and 2, and covery type3 and 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d9Q9dHUsjxJm"
   },
   "outputs": [],
   "source": [
    "# Create additional features to magnify the differences between cover type 1 and 2\n",
    "# Combine soil type 2,18,25,3,36,6,8,28,34 and wildness area 4 as only cover type 2 appers under these features\n",
    "train_df[\"type2stwa4\"] = train_df[\"Soil_Type6\"] + train_df[\"Wilderness_Area4\"] +  \\\n",
    "train_df[\"Soil_Type2\"]+ train_df[\"Soil_Type18\"] +  train_df[\"Soil_Type25\"] +  \\\n",
    "train_df[\"Soil_Type3\"] + train_df[\"Soil_Type36\"]+ \\\n",
    "train_df[\"Soil_Type8\"] + train_df[\"Soil_Type34\"]+ train_df[\"Soil_Type28\"]\n",
    "\n",
    "# Combine soil type 20, 23, 24, 31, 33 and 34 as only cover type 6 appears under these features but not cover type 3.\n",
    "train_df[\"type6st\"] = train_df[\"Soil_Type20\"] + train_df[\"Soil_Type23\"]+ \\\n",
    "train_df[\"Soil_Type24\"] +  train_df[\"Soil_Type31\"] + train_df[\"Soil_Type33\"] +  train_df[\"Soil_Type34\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OVpR8X4vRBGh"
   },
   "source": [
    "#### Drop Non-Existant Soil Types\n",
    "\n",
    "Now we'll drop soil types that don't exist in the training set. Then we will combine soil types 35, 38, 39 and 40 because they have a very similar distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7iT8zCZ2RBGi",
    "outputId": "023af93d-6351-4687-82a8-b90bb3adac38"
   },
   "outputs": [],
   "source": [
    "# Remove soil type 7 and 15 due to no data\n",
    "train_df.drop(columns=[\"Soil_Type7\", \"Soil_Type15\"], inplace=True)\n",
    "\n",
    "# Remove soil type 19, 37, 34, 21, 27,36,28,8,25 due to no limited data - TODO: should we be dropping these? \n",
    "train_df.drop(columns=[\"Soil_Type19\", \"Soil_Type37\",\"Soil_Type34\", \"Soil_Type21\",\"Soil_Type27\", \"Soil_Type36\",\"Soil_Type28\",\"Soil_Type8\", \"Soil_Type25\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine Similar Soil Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine soil type 35,38,39, 40\n",
    "train_df[\"soil_type35383940\"] = train_df[\"Soil_Type38\"] +  train_df[\"Soil_Type39\"] + train_df[\"Soil_Type40\"] +  train_df[\"Soil_Type35\"]\n",
    "# Combine soil type 10,11, 16, 17\n",
    "train_df[\"st10111617\"] = train_df[\"Soil_Type10\"] + train_df[\"Soil_Type11\"] + train_df[\"Soil_Type16\"] + train_df[\"Soil_Type17\"]\n",
    "# Combine soil type 9, 12\n",
    "train_df[\"st912\"] = train_df[\"Soil_Type9\"] + train_df[\"Soil_Type12\"] \n",
    "# Combine soil type 31,33\n",
    "train_df[\"st3133\"] = train_df[\"Soil_Type31\"] + train_df[\"Soil_Type33\"]\n",
    "# Combine soil type 23, 24\n",
    "train_df[\"st2324\"] = train_df[\"Soil_Type23\"] + train_df[\"Soil_Type24\"]\n",
    "# Combine soil type 6 and wilderness area 4\n",
    "train_df[\"st6w4\"] = train_df[\"Soil_Type6\"] + train_df[\"Wilderness_Area4\"]\n",
    "\n",
    "# train_df.drop(columns=[\"Soil_Type35\",\"Soil_Type38\", \"Soil_Type39\",'Soil_Type40','Soil_Type10','Soil_Type11','Soil_Type16','Soil_Type17','Soil_Type9','Soil_Type12','Soil_Type31','Soil_Type33','Soil_Type23','Soil_Type24','Soil_Type6','Wilderness_Area4'], inplace=True)\n",
    "\n",
    "# Check shape is as expected\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wZuK7AndohgG"
   },
   "source": [
    "#### Transform Aspect \n",
    "\n",
    "Now we'll transform the Asepct feature.\n",
    "TODO: Explain more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NDsS0rDjogRD",
    "outputId": "4685935a-5512-4811-a369-2c50940d9933"
   },
   "outputs": [],
   "source": [
    "# Convert aspect into sine and cosine values \n",
    "train_df[\"ap_ew\"] = np.sin(train_df[\"Aspect\"]/180*np.pi)\n",
    "train_df[\"ap_ns\"] = np.cos(train_df[\"Aspect\"]/180*np.pi)\n",
    "\n",
    "# Drop Aspect column\n",
    "train_df.drop(columns= [\"Aspect\"], inplace=True)\n",
    "              \n",
    "# Check shape is as expected\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "PsMf4ZAqoggM",
    "outputId": "78892119-0b4a-4747-d2bf-4fd0963dacf7"
   },
   "outputs": [],
   "source": [
    "# Visualize cover type VS the cosine of Aspect degerees\n",
    "fig,(ax1,ax2) = plt.subplots(1,2,figsize=(12,4))\n",
    "sns.violinplot(x=train_df['Cover_Type'],y=train_df['ap_ew'],ax=ax1)\n",
    "sns.histplot(train_df['ap_ew'],ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgCP2gE3pDjR"
   },
   "source": [
    "After the feature transformation, we see improved distinction in median values, espeically for cover type 6, where the median is notably higher than that of other cover types  and the distribution is concentrated around the median. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xf7E4Dv7Jyei"
   },
   "source": [
    "#### Log and Polynomial Transformations\n",
    "\n",
    "Now we'll log transform the features related to the distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dpmINoqU57Li",
    "outputId": "b31e9a71-1c9d-49af-f303-e8c9eaab4d2e"
   },
   "outputs": [],
   "source": [
    "# Complie a list of features to perform log transformation\n",
    "fe4_cols = ['Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n",
    "       'Horizontal_Distance_To_Roadways','Horizontal_Distance_To_Fire_Points']\n",
    "\n",
    "# Check the minimum value \n",
    "min_vertical_distance = train_df['Vertical_Distance_To_Hydrology'].min()\n",
    "print(\"Vertical_Distance_To_Hydrology Minimum: \", min_vertical_distance)\n",
    "\n",
    "# Add 147 to ensure no negative or 0 in the values \n",
    "train_df[fe4_cols] = train_df[fe4_cols] + 147\n",
    "\n",
    "# Log transform\n",
    "train_df[fe4_cols] = np.log(train_df[fe4_cols])\n",
    "\n",
    "# Add a polynominal feature\n",
    "train_df[\"elv_pwd\"] = train_df[\"Elevation\"]**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Id Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Can this be removed? We should drop id in the training data we actually use. \n",
    "# Make a copy of train_df for modelling\n",
    "train_df1 = train_df.copy()\n",
    "\n",
    "# Drop Id column as it is not a meaningful feature.\n",
    "train_df.drop(columns=[\"Id\"],inplace=True)\n",
    "test_df.drop(columns=[\"Id\"],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Hillshade_9am\n",
    "\n",
    "Hillshade_9am has a strong correlation with Hillshade_3pm and Aspect. TODO: If we're only dropping Hillshade_9am here we can drop it directly  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = set(train_data.columns.to_list())\n",
    "\n",
    "# Select features to drop. \n",
    "to_drop = set(['Hillshade_9am'])\n",
    "\n",
    "sel_features = list(all_features - to_drop)\n",
    "train_data =train_data[sel_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ESbQKHhFRBGm"
   },
   "source": [
    "#### Split Data into Train/Dev/Test\n",
    "\n",
    "Then, we split the training data into a training data set (80%) and development data set (20%). We will also have a large, separate test data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "id": "A8E-qeqURBGn",
    "outputId": "08edd245-eaec-4c64-a7d5-aed884f99e62"
   },
   "outputs": [],
   "source": [
    "# Split training data (labeled) into 80% training and 20% dev) and randomly sample \n",
    "training_data = train_df.sample(frac=0.8)\n",
    "dev_data_df = train_df.drop(training_data.index)\n",
    "\n",
    "# Examine shape of both data sets\n",
    "print(training_data.shape)\n",
    "print(dev_data_df.shape)\n",
    "\n",
    "# Briefly examine feature attributes for the training data \n",
    "training_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ORB17ckvRBGq",
    "outputId": "2e7dc9a2-cb71-4469-d545-b9fa95d12866"
   },
   "outputs": [],
   "source": [
    "# Split into data and labels\n",
    "train_data = training_data.drop(columns=[\"Cover_Type\"])\n",
    "train_labels = training_data[\"Cover_Type\"]\n",
    "dev_data = dev_data_df.drop(columns=[\"Cover_Type\"])\n",
    "dev_labels = dev_data_df[\"Cover_Type\"]\n",
    "test_data = test_df\n",
    "\n",
    "# Double check the shape\n",
    "print(train_data.shape)\n",
    "print(dev_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e020Gy6-RBGq"
   },
   "source": [
    "#### Scale Data\n",
    "Additionally, we will scale the training data to have a mean of 0 and a variance of 1. Then we will retrieve the original training mean and variance for each feature and use that to standardize the development data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YbrgEHOVXz8e"
   },
   "outputs": [],
   "source": [
    "#compile a list for columns for scaling\n",
    "ss_cols = ['Elevation','Slope', 'Horizontal_Distance_To_Hydrology',\n",
    "       'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n",
    "       'Horizontal_Distance_To_Fire_Points','elv_pwd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T34BrVQIRBGu",
    "outputId": "ade2e4f8-7787-4726-d4ec-9352ddc288ed"
   },
   "outputs": [],
   "source": [
    "# Normalize features using the standard scaler [training data]\n",
    "def scaler(ss=\"\",cols=ss_cols):\n",
    "    if ss == \"minmax\":\n",
    "        scaler = MinMaxScaler()\n",
    "    else :\n",
    "        scaler = StandardScaler()\n",
    "        model = scaler.fit(train_data[cols])\n",
    "    train_data[cols] = model.transform(train_data[cols])\n",
    "    # Normalize features using the standard scaler [dev data]\n",
    "    dev_data[cols] = model.transform(dev_data[cols])\n",
    "\n",
    "scaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A4xIoBuxRBGy",
    "outputId": "a99023d4-4f4e-4bfb-dbbe-412d47f36629"
   },
   "outputs": [],
   "source": [
    "# Explore and confirm the shape of the data\n",
    "print(\"Training data shape: {0} Training labels shape: {1}\\n\".format(train_data.shape, train_labels.shape))\n",
    "print(\"Dev data shape: {0} Dev labels shape: {1}\\n\".format(dev_data.shape, dev_data.shape))\n",
    "print(\"Test data shape: \", test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvcBF_kJRBG3"
   },
   "source": [
    "## Models\n",
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zRzodyXmRBG3",
    "outputId": "cc7a36f4-a249-475f-f4c3-448549d6354b"
   },
   "outputs": [],
   "source": [
    "# Try a random forest - before any data cleaning \n",
    "def RandomForest(num_trees):\n",
    "    model = RandomForestClassifier(num_trees,max_depth=8)\n",
    "    model.fit(train_data, train_labels)\n",
    "    predictions = model.predict(dev_data)\n",
    "    score = model.score(dev_data, dev_labels)\n",
    "    probabilities = model.predict_proba(dev_data)\n",
    "    print(\"Random Forest Performance for {0} trees: {1}\".format(num_trees,score))\n",
    "    # Plot_confusion_matrix\n",
    "    plot_confusion_matrix(model, dev_data, dev_labels, values_format = \"d\")\n",
    "    plt.title(\"{} Tree Random Forest Confusion Matrix:\".format(num_trees))\n",
    "    plt.plot()\n",
    "    mse_forest = mean_squared_error(dev_labels, predictions)\n",
    "    print(\"Mean Squared Error: \", mse_forest)\n",
    "    return score, probabilities\n",
    "    \n",
    "num_trees_list = [1,3,5,10,100]\n",
    "random_forest_results = {}\n",
    "for num_trees in num_trees_list:\n",
    "    score, probabilities = RandomForest(num_trees)\n",
    "    random_forest_results[score] = probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ie2UMwSPRBG5"
   },
   "source": [
    "#### Naive Bayes (Bernoulli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "llTEtjHNRBG6",
    "outputId": "de4c4eee-4d79-4112-d692-02cfc8bdad87"
   },
   "outputs": [],
   "source": [
    "# Try Naive Bayes - Bernoulli \n",
    "def NB(alf):\n",
    "    model = BernoulliNB(alpha = alf)\n",
    "    model.fit(train_data, train_labels)\n",
    "    predictions = model.predict(dev_data)\n",
    "    score = model.score(dev_data, dev_labels)\n",
    "    print(\"BernoulliNB for alph = {0}: accuracy = {1}\".format(alf,score))\n",
    "    # Plot Confusion Matrix\n",
    "    plot_confusion_matrix(model, dev_data, dev_labels, values_format = \"d\")\n",
    "    plt.title(\"NB Confusion Matrix with alpha: {}\".format(alf))\n",
    "    plt.plot()\n",
    "    print('\\n\\n')\n",
    "    \n",
    "# the alpha isn't actually making a difference \n",
    "# alphas_list = [0.00001,0.001, 0.01, 0.1, 1, 10]\n",
    "alphas_list = [0.01]\n",
    "for alpha in alphas_list:\n",
    "    NB(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0Cfzu77m_7-"
   },
   "outputs": [],
   "source": [
    "# # Try Naive Bayes - multi-nominal\n",
    "# def MNB(alf):\n",
    "#     model = MultinomialNB(alpha = alf)\n",
    "#     model.fit(train_data, train_labels)\n",
    "#     predictions = model.predict(dev_data)\n",
    "#     score = model.score(dev_data, dev_labels)\n",
    "#     print(\"Multi NB for alph = {0}: accuracy = {1}\".format(alf,score))\n",
    "#     # Plot Confusion Matrix\n",
    "#     plot_confusion_matrix(model, dev_data, dev_labels, values_format = \"d\")\n",
    "#     plt.title(\"Multi NB Confusion Matrix with alpha: {}\".format(alf))\n",
    "#     plt.plot()\n",
    "#     print('\\n\\n')\n",
    "    \n",
    "# # the alpha isn't actually making a difference \n",
    "# # alphas_list = [0.00001,0.001, 0.01, 0.1, 1, 10]\n",
    "# alphas_list = [1.0]\n",
    "# for alpha in alphas_list:\n",
    "#     MNB(alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tx4b8LpURBG8"
   },
   "source": [
    "#### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ExCF6N3xRBG9",
    "outputId": "61334f21-000d-432a-d16a-90ce1de7d41e"
   },
   "outputs": [],
   "source": [
    "# Try K Nearest Neighbors - before any data cleaning \n",
    "def KNN(kn):\n",
    "    model = KNeighborsClassifier(n_neighbors = kn)\n",
    "    model.fit(train_data, train_labels)\n",
    "    predictions = model.predict(dev_data)\n",
    "    score = model.score(dev_data, dev_labels)\n",
    "    print(\"KNN {0} neighbors : accuracy = {1}\".format(kn,score))\n",
    "    probabilities = model.predict_proba(dev_data)\n",
    "    # Plot Confusion Matrix\n",
    "    plot_confusion_matrix(model, dev_data, dev_labels, values_format = \"d\")\n",
    "    plt.title(\"KNN Confusion Matrix with {} Neighbors\".format(kn))\n",
    "    plt.plot()\n",
    "    mse_knn = mean_squared_error(dev_labels, predictions)\n",
    "    print(\"Mean Squared Error: \", mse_knn)\n",
    "    return score, probabilities\n",
    "    \n",
    "# The alpha isn't actually making a difference \n",
    "neigh_list = [1,2,4, 7, 10]\n",
    "knn_results = {}\n",
    "for neigh in neigh_list:\n",
    "    score, probabilities = KNN(neigh)\n",
    "    knn_results[score] = probabilities "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9tO8GCQIRBG_"
   },
   "source": [
    "#### Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "id": "_sYGejCORBG_",
    "outputId": "6cabe738-19f6-4045-bd66-9ee1f0f6a3fe"
   },
   "outputs": [],
   "source": [
    "# Try Multi-Layer Perceptron - before any data cleaning \n",
    "def MLP():\n",
    "    #    model = MLPClassifier(solver='adam', alpha=1e-6, hidden_layer_sizes=(100, ), random_state=0) .8257\n",
    "    #    model = MLPClassifier(solver='adam', alpha=1e-3, hidden_layer_sizes=(100, ), random_state=0)  .82969\n",
    "    #    model = MLPClassifier(solver='adam', alpha=1e-3, hidden_layer_sizes=(200, ), random_state=0) .837\n",
    "    #    model = MLPClassifier(solver='adam', alpha=1e-3, hidden_layer_sizes=(100, ), random_state=0, activation='tanh') .83068\n",
    "\n",
    "    # Default activation is 'relu', random state lets us get the same result every time (so we can tune other parameters)\n",
    "    # max_iter is 200 by default, but more helps. alpha is the regularization parameter. solver is 'adam' by default\n",
    "    model = MLPClassifier(alpha=1e-3, hidden_layer_sizes=(200,), random_state=0, max_iter=300) \n",
    "    model.fit(train_data, train_labels) \n",
    "    predictions = model.predict(dev_data)\n",
    "    score = model.score(dev_data, dev_labels)\n",
    "    probabilities = model.predict_proba(dev_data)\n",
    "    plot_confusion_matrix(model, dev_data, dev_labels, values_format = \"d\")\n",
    "    plt.title(\"MLP Confusion Matrix\")\n",
    "    plt.plot()\n",
    "    print(\"MLP accuracy = \",score)\n",
    "    mse_nn = mean_squared_error(dev_labels, predictions)\n",
    "    print(\"Mean Squared Error: \", mse_nn)\n",
    "    return score, probabilities\n",
    "\n",
    "mlp_results = {}\n",
    "score, probabilities = MLP()\n",
    "mlp_results[score] = probabilities "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Vta0OkyT-AM"
   },
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VJb8RxsucrLx",
    "outputId": "8573fecf-0537-4809-fe8d-909d48b0f4a1"
   },
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "def LR():\n",
    "    model = LogisticRegression(random_state=0, multi_class='ovr',solver='lbfgs', max_iter = 300)\n",
    "    model.fit(train_data, train_labels)\n",
    "    score = model.score(dev_data,dev_labels)\n",
    "    print(\"Logistic Regression accuracy = \",score)\n",
    "LR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(1, 53)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# # Retrieve predictions \n",
    "predictions = model(train_data[:1]).numpy()\n",
    "# # Convert logits to probabilities\n",
    "tf.nn.softmax(predictions).numpy()\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_data, train_labels, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(dev_data,  dev_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble\n",
    "\n",
    "Here we will combine the three best performing models and implement a \"voting\" system to try to improve accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ensemble():\n",
    "    # Find max score from each model. best_scores shape: (3,)\n",
    "    best_scores = [max(mlp_results.keys()), max(knn_results.keys()),max(random_forest_results.keys())]\n",
    "    # Find maximum probability for each example for each model. prediction_probabilities shape: (3024, 3)\n",
    "    prediction_probabilities = [np.max(mlp_results[best_scores[0]],axis=1),np.max(knn_results[best_scores[1]],axis=1),np.max(random_forest_results[best_scores[2]],axis=1)]\n",
    "    prediction_probabilities = np.transpose(np.array(prediction_probabilities))\n",
    "    # Find highest predicted label. predicted_classes shape: (3024, 3)\n",
    "    predicted_classes = [np.argmax(mlp_results[best_scores[0]],axis=1),np.argmax(knn_results[best_scores[1]],axis=1),np.argmax(random_forest_results[best_scores[2]],axis=1)]\n",
    "    predicted_classes = np.transpose(np.array(predicted_classes))\n",
    "    \n",
    "    # Determine final predictions\n",
    "    new_predictions = []\n",
    "    # Keep track of instances in which the models disagree for insight \n",
    "    count = 0\n",
    "    for i, row in enumerate(predicted_classes):\n",
    "        # Count instances of each class in the predictions\n",
    "        unique, counts = np.unique(row, return_counts=True)\n",
    "        zipped = dict(zip(unique, counts))\n",
    "        # Initialize Classification\n",
    "        classification = 0\n",
    "        # If there's only 1 unique value, all models agreed\n",
    "        if len(unique) == 1:\n",
    "            classification = unique[0]\n",
    "        # Two out of three models agreed\n",
    "        elif len(unique) == 2:\n",
    "            count += 1\n",
    "            classification = unique[np.argmax(counts)]\n",
    "        # All three models disagree. Choose the label with the highest probability \n",
    "        else:\n",
    "            count += 1\n",
    "            classification = prediction_probabilities[i][0]\n",
    "        # Assign the new prediction\n",
    "        new_predictions.append(classification)\n",
    "    print(\"Models disagreed on {0}/{1} dev examples.\".format(count, dev_labels.shape[0]))\n",
    "    return np.array(new_predictions).astype(int)\n",
    "\n",
    "new_predictions = Ensemble()\n",
    "mse_ensemble = mean_squared_error(dev_labels, new_predictions)\n",
    "accuracy = accuracy_score(dev_labels, new_predictions)\n",
    "print(\"Mean Squared Error: \", mse_ensemble)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine and Compare Histograms of Predictions\n",
    "fig, axes = plt.subplots(2,2)\n",
    "# Ensemble\n",
    "axes[0,0].hist(new_predictions, bins=7,color = 'red') \n",
    "# MLP\n",
    "axes[0,1].hist(predicted_classes[:,0], bins=7, color = 'orange') \n",
    "# KNN\n",
    "axes[1,0].hist(predicted_classes[:,1], bins=7, color = 'green') \n",
    "# Random Forest\n",
    "axes[1,1].hist(predicted_classes[:,2], bins=7, color = 'blue') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkdOOJi0RBHB"
   },
   "source": [
    "### End matter\n",
    "\n",
    "#### Acknowledgements/Sources\n",
    "\n",
    "* That helpful stack overflow post\n",
    "  * https://stackoverflow.com/questions/28663856/how-to-count-the-occurrence-of-certain-item-in-an-ndarray\n",
    "* Relevant Documentation\n",
    "  * KNeighborsClassifier\n",
    "    * https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "  * Pretty Confusion Matrix\n",
    "    * https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html\n",
    "  * Preprocessing\n",
    "    * https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.normalize.html\n",
    "* Soil information\n",
    "  * https://www.uidaho.edu/cals/soil-orders/aridisols\n",
    "  \n",
    "#### Backup Formats\n",
    "\n",
    "*because sometimes you just want to look at the markdown or whatever real quick*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QSnMBvI2RBHC",
    "outputId": "d2a9010d-2b5d-4e46-f559-4a01e6e6f948"
   },
   "outputs": [],
   "source": [
    "#Create a backup of the jupyter notebook in a format for where changes are easier to see.\n",
    "!jupyter nbconvert clear_cut_solution.ipynb --to=\"python\" --output=\"backups/clear-cut-solution\"\n",
    "!jupyter nbconvert clear_cut_solution.ipynb --to markdown --output=\"backups/clear-cut-solution\"\n",
    "\n",
    "# Also archiving this bad boy\n",
    "!jupyter nbconvert clear_cut_solution.ipynb --to html --output=\"backups/clear-cut-solution\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "clear-cut-solution.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m56",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m56"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
